# Configuration for MLX Custom Metal Kernel Attention Optimization
max_iterations: 100
checkpoint_interval: 10
log_level: "INFO"

# LLM configuration - Use stronger models for complex Metal kernel optimization
llm:
  primary_model: "gemini-2.5-flash-preview-05-20"
  primary_model_weight: 0.6  
  secondary_model: "gemini-2.5-pro-preview-05-06" 
  secondary_model_weight: 0.4
  api_base: "https://generativelanguage.googleapis.com/v1beta/openai/"
  temperature: 0.9  # Higher for more exploration in kernel optimization
  top_p: 0.95
  max_tokens: 32000  
  timeout: 600

# Prompt configuration
prompt:
  system_message: |
    This is a high-performance custom Metal kernel optimization task using MLX's metal_kernel API.
    
    MISSION: Create custom Metal GPU kernels that beat mx.fast.scaled_dot_product_attention
    - ACCURACY: Must maintain numerical equivalence (MSE < 1e-6) for drop-in replacement
    - PERFORMANCE: Must exceed mx.fast.scaled_dot_product_attention speed
    - METHOD: Use mx.fast.metal_kernel() to write high-performance Metal C++ code
    
    CUSTOM METAL KERNEL STRATEGY for Maximum Performance:
    
    🚀 HIGH-PERFORMANCE METAL KERNELS (PRIMARY FOCUS):
    - mx.fast.metal_kernel() → Direct Metal C++ kernel implementation
    - Fused attention kernels → Combine QK^T + scale + mask + softmax + output in one kernel
    - Memory access optimization → Coalesced reads, efficient threadgroup dispatch
    - Template programming → Type specialization for float16/float32
    - Vectorized operations → Use Metal vector types (float4, half4, etc.)
    - Threadgroup memory → Shared memory for cache optimization
    - Atomic operations → For complex reductions and synchronized updates
    - Specialized kernels → Different kernels for different scenarios (GQA, masking)
    
    💯 METAL C++ OPTIMIZATION PATTERNS (ESSENTIAL):
    
    🚨 CRITICAL API USAGE (AVOID ERRORS):
    
    **DO NOT** add invalid parameters to kernel calls:
    ```python
    # ❌ WRONG - these parameters don't exist:
    kernel(inputs=[...], ensure_row_contiguous=True)  # WRONG!
    kernel(inputs=[...], constants={...})             # WRONG!
    
    # ✅ CORRECT - only these parameters allowed:
    kernel(
        inputs=[...],           # Required
        template=[...],         # Required  
        output_shapes=[...],    # Required
        output_dtypes=[...],    # Required
        grid=(...),            # Required
        threadgroup=(...),     # Required
        init_value=0.0,        # Optional
        verbose=False,         # Optional
        stream=None            # Optional
    )
    ```
    
    **Metal Kernel Creation** (where ensure_row_contiguous goes):
    ```python
    kernel = mx.fast.metal_kernel(
        name="...",
        input_names=[...],
        output_names=[...], 
        source=metal_code,
        ensure_row_contiguous=True  # ✅ HERE is where this parameter belongs
    )
    ```
    
    **Correct Metal C++ Kernel Structure**:
    ```cpp
    template <typename T>
    [[kernel]] void fused_attention_kernel(
        const device T* q [[buffer(0)]],
        const device T* k [[buffer(1)]],
        const device T* v [[buffer(2)]],
        device T* out [[buffer(3)]],
        uint3 thread_position_in_grid [[thread_position_in_grid]],
        uint3 threads_per_threadgroup [[threads_per_threadgroup]],
        uint thread_index_in_threadgroup [[thread_index_in_threadgroup]]
    ) {
        // Fuse all attention operations for maximum efficiency
        // Use threadgroup_barrier for synchronization
        // Optimize memory access patterns
    }
    ```
    
    **Correct Metal Kernel API Usage**:
    ```python
    # Create kernel
    kernel = mx.fast.metal_kernel(
        name="kernel_name",
        input_names=["input1", "input2"],
        output_names=["output1"],
        source=metal_code_string,
        ensure_row_contiguous=True  # THIS parameter goes on metal_kernel creation
    )
    
    # Call kernel - THESE are the only valid parameters:
    outputs = kernel(
        inputs=[array1, array2],
        template=[("T", mx.float16)],
        output_shapes=[(B, H, L, D)],
        output_dtypes=[mx.float16],
        grid=(total_threads, 1, 1),
        threadgroup=(256, 1, 1),
        # Optional parameters:
        init_value=0.0,    # Initialize outputs to this value
        verbose=False,      # Print generated kernel code
        stream=None         # MLX stream
    )
    ```
    
    2. **Memory Access Optimization**:
    - Coalesced memory reads (threads access contiguous memory)
    - Threadgroup memory for shared data
    - Minimize global memory bandwidth usage
    - Use vectorized loads/stores (float4, half4)
    - Avoid memory bank conflicts
    
    3. **Threadgroup Strategy**:
    - Optimal threadgroup size (usually 256 or 512)
    - Thread distribution across heads and sequence dimensions
    - Efficient grid dispatch patterns
    - Use threadgroup barriers for synchronization
    
    4. **Kernel Fusion Opportunities**:
    - QK^T computation + scaling in one pass
    - Mask application + softmax computation
    - Softmax + attention weight application to values
    - Full end-to-end fused attention kernel
    
    5. **Apple Silicon GPU Optimization**:
    - Leverage unified memory architecture
    - Optimize for Metal tile-based deferred rendering
    - Use appropriate vector types for hardware
    - Minimize memory latency with cache-friendly patterns
    
    🎯 CONCRETE OPTIMIZATION TECHNIQUES:
    
    **Tiled Attention Implementation**:
    ```cpp
    // Process attention in tiles for cache efficiency
    const uint tile_size = 64;
    threadgroup T shared_q[tile_size * head_dim];
    threadgroup T shared_k[tile_size * head_dim];
    
    for (uint tile = 0; tile < ceildiv(seq_len, tile_size); tile++) {
        // Load tile into threadgroup memory
        // Compute attention for this tile
        // Write results back efficiently
    }
    ```
    
    **Vectorized Computation**:
    ```cpp
    // Use vector types for better throughput
    using VecT = typename VectorType<T, 4>::type;
    const device VecT* q_vec = reinterpret_cast<const device VecT*>(q);
    device VecT* out_vec = reinterpret_cast<device VecT*>(out);
    ```
    
    **Specialized Kernels**:
    - Different kernels for different sequence lengths
    - GQA-specific kernels with optimized broadcasting
    - Causal mask kernels with triangular computation patterns
    - Boolean mask kernels with conditional execution
    
    ⚡ PERFORMANCE OPTIMIZATION PRIORITIES:
    
    1. **Memory Bandwidth** (CRITICAL):
       - Minimize global memory accesses
       - Maximize memory coalescing
       - Use threadgroup memory effectively
       - Vectorize memory operations
    
    2. **Kernel Fusion** (HIGH IMPACT):
       - Combine multiple operations in single kernel
       - Reduce intermediate memory allocations
       - Minimize kernel launch overhead
    
    3. **Thread Utilization** (ESSENTIAL):
       - Optimal threadgroup sizing
       - Balanced workload distribution
       - Minimize thread divergence
       - Use SIMD operations effectively
    
    4. **Cache Optimization** (APPLE SILICON SPECIFIC):
       - Tile-based computation patterns
       - Locality-aware data access
       - Minimize cache misses
    
    🚫 PERFORMANCE ANTI-PATTERNS (AVOID):
    - Non-coalesced memory access patterns
    - Excessive global memory bandwidth usage
    - Thread divergence in conditional operations
    - Inefficient threadgroup dispatch
    - Multiple kernel launches for single logical operation
    - Unnecessary data type conversions
    - Poor cache locality patterns
    
    EVOLUTION STRATEGY:
    1. **Start with fused kernels** for simple cases (no masking, standard attention)
    2. **Optimize memory access patterns** using vectorization and coalescing
    3. **Add specialized kernels** for GQA, causal masking, boolean masking
    4. **Implement tiled computation** for large sequence lengths
    5. **Fine-tune threadgroup dispatch** for optimal GPU utilization
    6. **Profile and optimize** hot paths and memory bottlenecks
    
    BENCHMARK TARGET: 
    - Must handle all spda_benchmark.py configurations (seq 32-4096, GQA, masks)
    - Target: 15-30% speedup over mx.fast.scaled_dot_product_attention (AlphaEvolve achieved 23% for Gemini kernels)
    - Accuracy: MSE < 1e-6 vs reference (non-negotiable)
    - Method: Custom Metal C++ kernels, not just basic operations
    
    COMPETITIVE ADVANTAGE:
    mx.fast.scaled_dot_product_attention is likely implemented with optimized kernels,
    but custom Metal kernels can potentially discover:
    - Novel tiling strategies for Apple Silicon architecture
    - Better memory access patterns for unified memory
    - Optimized kernel fusion opportunities
    - Specialized computation patterns for different input sizes
    - Hardware-specific optimizations not available in general implementations
    
    Focus on writing high-performance Metal C++ code that leverages:
    - Direct GPU execution without CPU overhead
    - Apple Silicon's unified memory architecture
    - Metal's threadgroup and SIMD capabilities
    - Optimal memory bandwidth utilization
    - Custom optimizations for attention-specific patterns
  
  num_top_programs: 5
  num_diverse_programs: 3
  use_template_stochasticity: true

# Database configuration - Larger population for complex kernel optimization
database:
  db_path: "./openevolve_output/program_db" 
  population_size: 120  # Larger for kernel optimization complexity
  archive_size: 40
  num_islands: 6
  elite_selection_ratio: 0.12
  exploitation_ratio: 0.6
  exploration_ratio: 0.28

# Evaluator configuration
evaluator:
  timeout: 900  # Longer timeout for kernel compilation and testing
  cascade_evaluation: true
  cascade_thresholds: [0.8, 0.9]  
  parallel_evaluations: 2  # Lower to avoid GPU resource contention
  use_llm_feedback: false

# Evolution settings
diff_based_evolution: true
allow_full_rewrites: false
max_code_length: 60000  # Allow larger code for complex Metal kernels
